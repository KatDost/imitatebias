
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://example.com/mimic/">
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.0, mkdocs-material-8.5.6">
    
    
      
        <title>Mimic - imitatebias Documentation</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.20d9efc8.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.cbb835fc.min.css">
        
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#imitatebias.mimic" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="imitatebias Documentation" class="md-header__button md-logo" aria-label="imitatebias Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            imitatebias Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Mimic
            
          </span>
        </div>
      </div>
    </div>
    
    
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="imitatebias Documentation" class="md-nav__button md-logo" aria-label="imitatebias Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    imitatebias Documentation
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../imitate/" class="md-nav__link">
        Imitate
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Mimic
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Mimic
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#imitatebias.mimic" class="md-nav__link">
    imitatebias.mimic
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#imitatebias.mimic.Mimic" class="md-nav__link">
    Mimic
  </a>
  
    <nav class="md-nav" aria-label="Mimic">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#imitatebias.mimic.Mimic--methods" class="md-nav__link">
    Methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#imitatebias.mimic.Mimic--references" class="md-nav__link">
    References
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#imitatebias.mimic.Mimic.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#imitatebias.mimic.Mimic.augment" class="md-nav__link">
    augment()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#imitatebias.mimic.Mimic.fit" class="md-nav__link">
    fit()
  </a>
  
    <nav class="md-nav" aria-label="fit()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#imitatebias.mimic.Mimic.fit--references" class="md-nav__link">
    References
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#imitatebias.mimic.Mimic.predict_cluster" class="md-nav__link">
    predict_cluster()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../cancels/" class="md-nav__link">
        Cancels
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../generators/" class="md-nav__link">
        Data and Bias Generators
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#imitatebias.mimic" class="md-nav__link">
    imitatebias.mimic
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#imitatebias.mimic.Mimic" class="md-nav__link">
    Mimic
  </a>
  
    <nav class="md-nav" aria-label="Mimic">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#imitatebias.mimic.Mimic--methods" class="md-nav__link">
    Methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#imitatebias.mimic.Mimic--references" class="md-nav__link">
    References
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#imitatebias.mimic.Mimic.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#imitatebias.mimic.Mimic.augment" class="md-nav__link">
    augment()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#imitatebias.mimic.Mimic.fit" class="md-nav__link">
    fit()
  </a>
  
    <nav class="md-nav" aria-label="fit()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#imitatebias.mimic.Mimic.fit--references" class="md-nav__link">
    References
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#imitatebias.mimic.Mimic.predict_cluster" class="md-nav__link">
    predict_cluster()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  <h1>Mimic</h1>

<div class="doc doc-object doc-module">


<a id="imitatebias.mimic"></a>
  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="imitatebias.mimic.Mimic" class="doc doc-heading">
        <code>Mimic</code>


</h2>


  <div class="doc doc-contents ">

  
      <p>Mimic generates points to mitigate a multi-cluster dataset's bias.</p>
<p>Machine Learning can help overcome human biases in decision making by focussing 
on purely logical conclusions based on the training data. If the training data 
is biased, however, that bias will be transferred to the model and remains 
undetected as the performance is validated on a test set drawn from the same 
biased distribution.
Existing strategies for selection bias identification and mitigation generally 
rely on some sort of knowledge of the bias or the ground-truth. An exception 
is the Imitate [1]<em> algorithm that assumes no knowledge but comes with a strong 
limitation: It can only model datasets with one normally distributed cluster 
per class.
MIMIC uses Imitate as a building block but relaxes this limitation. By allowing 
mixtures of multivariate Gaussians, our technique is able to model multi-cluster 
datasets and provide solutions for a substantially wider set of problems. <br />
See our paper [2]</em> for details.</p>

  <p><strong>Attributes:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>params</code></td>
          <td>
                <code>dict(int: numpy.ndarray (2D))</code>
          </td>
          <td><p>A label-indexed dictionary containing (mean, cov) tuples for each identified
cluster belonging to this label.</p></td>
        </tr>
        <tr>
          <td><code>data</code></td>
          <td>
                <code>numpy.ndarray (2D)</code>
          </td>
          <td><p>The dataset Mimic is fitted to.</p></td>
        </tr>
        <tr>
          <td><code>labels</code></td>
          <td>
                <code>numpy.array (1D)</code>
          </td>
          <td><p>The corresponding labels. Labels need to be integer values.</p></td>
        </tr>
    </tbody>
  </table>
      <h4 id="imitatebias.mimic.Mimic--methods">Methods</h4>
<p>fit(data, labels=[], centers=None)
    Fits the Mimic Gaussians to a dataset.
predict_cluster(which_class)
    Predicts clusters for the input dataset.
augment()
    Augments the fitted dataset to mitigate its bias.</p>
<h4 id="imitatebias.mimic.Mimic--references">References</h4>
<p>.. [1] Katharina Dost, Katerina Taskova, Patricia Riddle, and Jörg Wicker. 
   "Your Best Guess When You Know Nothing: Identification and Mitigation of 
   Selection Bias." In: 2020 IEEE International Conference on Data Mining (ICDM), 
   pp. 996-1001, IEEE, 2020, ISSN: 2374-8486.</p>
<p>.. [2] Katharina Dost, Hamish Duncanson, Ioannis Ziogas, Patricia Riddle, and Jörg
   Wicker. "Divide and Imitate: Multi-Cluster Identification and Mitigation of 
   Selection Bias." In: Advances in Knowledge Discovery and Data Mining - 26th 
   Pacific-Asia Conference, PAKDD 2022. Lecture Notes in Computer Science, vol. 
   13281, pp. 149-160. Springer, Cham (2022).</p>

<p><strong>Examples:</strong></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">imitatebias.generators</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">imitatebias.mimic</span> <span class="kn">import</span> <span class="o">*</span>
</code></pre></div>
    <p>Generate a dataset.</p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">generateData</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2210</span><span class="p">)</span>
</code></pre></div>
    <p>Generate a biased dataset.</p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">X_b</span><span class="p">,</span> <span class="n">y_b</span><span class="p">,</span> <span class="n">idcs_deleted</span> <span class="o">=</span> <span class="n">generateBias</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2210</span><span class="p">)</span>
</code></pre></div>
    <p>initialize Mimic</p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">mim</span> <span class="o">=</span> <span class="n">Mimic</span><span class="p">()</span>
</code></pre></div>
    <p>fit to the biased dataset</p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">mim</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_b</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">y_b</span><span class="p">)</span>
</code></pre></div>
    <p>predict cluster assignment for class 0</p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">predicted_clusters</span> <span class="o">=</span> <span class="n">mim</span><span class="o">.</span><span class="n">predict_cluster</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>
    <p>plot the resulting clusters for class 0</p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_b</span><span class="p">[</span><span class="n">y_b</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_b</span><span class="p">[</span><span class="n">y_b</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">predicted_clusters</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
    <p>augment the data</p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">gen_p</span><span class="p">,</span> <span class="n">gen_l</span> <span class="o">=</span> <span class="n">mim</span><span class="o">.</span><span class="n">augment</span><span class="p">()</span>
</code></pre></div>
    <p>plot the result</p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_b</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_b</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;dataset&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">gen_p</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">gen_p</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;generated points&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>


        <details class="quote">
          <summary>Source code in <code>imitatebias\mimic.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Mimic</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Mimic generates points to mitigate a multi-cluster dataset&#39;s bias.</span>

<span class="sd">    Machine Learning can help overcome human biases in decision making by focussing </span>
<span class="sd">    on purely logical conclusions based on the training data. If the training data </span>
<span class="sd">    is biased, however, that bias will be transferred to the model and remains </span>
<span class="sd">    undetected as the performance is validated on a test set drawn from the same </span>
<span class="sd">    biased distribution.</span>
<span class="sd">    Existing strategies for selection bias identification and mitigation generally </span>
<span class="sd">    rely on some sort of knowledge of the bias or the ground-truth. An exception </span>
<span class="sd">    is the Imitate [1]_ algorithm that assumes no knowledge but comes with a strong </span>
<span class="sd">    limitation: It can only model datasets with one normally distributed cluster </span>
<span class="sd">    per class.</span>
<span class="sd">    MIMIC uses Imitate as a building block but relaxes this limitation. By allowing </span>
<span class="sd">    mixtures of multivariate Gaussians, our technique is able to model multi-cluster </span>
<span class="sd">    datasets and provide solutions for a substantially wider set of problems.   </span>
<span class="sd">    See our paper [2]_ for details.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    params : dict(int: numpy.ndarray (2D))</span>
<span class="sd">        A label-indexed dictionary containing (mean, cov) tuples for each identified</span>
<span class="sd">        cluster belonging to this label.</span>
<span class="sd">    data : numpy.ndarray (2D)</span>
<span class="sd">        The dataset Mimic is fitted to.</span>
<span class="sd">    labels : numpy.array (1D)</span>
<span class="sd">        The corresponding labels. Labels need to be integer values.</span>

<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    fit(data, labels=[], centers=None)</span>
<span class="sd">        Fits the Mimic Gaussians to a dataset.</span>
<span class="sd">    predict_cluster(which_class)</span>
<span class="sd">        Predicts clusters for the input dataset.</span>
<span class="sd">    augment()</span>
<span class="sd">        Augments the fitted dataset to mitigate its bias.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Katharina Dost, Katerina Taskova, Patricia Riddle, and Jörg Wicker. </span>
<span class="sd">       &quot;Your Best Guess When You Know Nothing: Identification and Mitigation of </span>
<span class="sd">       Selection Bias.&quot; In: 2020 IEEE International Conference on Data Mining (ICDM), </span>
<span class="sd">       pp. 996-1001, IEEE, 2020, ISSN: 2374-8486.</span>

<span class="sd">    .. [2] Katharina Dost, Hamish Duncanson, Ioannis Ziogas, Patricia Riddle, and Jörg</span>
<span class="sd">       Wicker. &quot;Divide and Imitate: Multi-Cluster Identification and Mitigation of </span>
<span class="sd">       Selection Bias.&quot; In: Advances in Knowledge Discovery and Data Mining - 26th </span>
<span class="sd">       Pacific-Asia Conference, PAKDD 2022. Lecture Notes in Computer Science, vol. </span>
<span class="sd">       13281, pp. 149-160. Springer, Cham (2022).</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from imitatebias.generators import *</span>
<span class="sd">    &gt;&gt;&gt; from imitatebias.mimic import *</span>

<span class="sd">    Generate a dataset.</span>
<span class="sd">    &gt;&gt;&gt; X, y = generateData(1000, 2, 2, seed=2210)</span>

<span class="sd">    Generate a biased dataset.</span>
<span class="sd">    &gt;&gt;&gt; X_b, y_b, idcs_deleted = generateBias(X, y, 1, seed=2210)</span>

<span class="sd">    initialize Mimic</span>
<span class="sd">    &gt;&gt;&gt; mim = Mimic()</span>

<span class="sd">    fit to the biased dataset</span>
<span class="sd">    &gt;&gt;&gt; mim.fit(X_b, labels=y_b)</span>

<span class="sd">    predict cluster assignment for class 0</span>
<span class="sd">    &gt;&gt;&gt; predicted_clusters = mim.predict_cluster(0)</span>

<span class="sd">    plot the resulting clusters for class 0</span>
<span class="sd">    &gt;&gt;&gt; plt.scatter(X_b[y_b == 0, 0], X_b[y_b == 0, 1], c=predicted_clusters)</span>
<span class="sd">    &gt;&gt;&gt; plt.show()</span>

<span class="sd">    augment the data</span>
<span class="sd">    &gt;&gt;&gt; gen_p, gen_l = mim.augment()</span>

<span class="sd">    plot the result</span>
<span class="sd">    &gt;&gt;&gt; plt.scatter(X_b[:,0], X_b[:,1], label=&#39;dataset&#39;)</span>
<span class="sd">    &gt;&gt;&gt; plt.scatter(gen_p[:,0], gen_p[:,1], label=&#39;generated points&#39;)</span>
<span class="sd">    &gt;&gt;&gt; plt.legend()</span>
<span class="sd">    &gt;&gt;&gt; plt.show()</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Mimic Constructor.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[],</span> <span class="n">centers</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Fits a bias-aware multivariate Gaussian Mixture Model per label to the data.</span>

<span class="sd">        See our paper [1]_ for details. This process is slow and substantially less</span>
<span class="sd">        powerful than the Imitate algorithm since it additionally needs to cluster the</span>
<span class="sd">        dataset into potentially biased overlapping clusters. We only recommend Mimic</span>
<span class="sd">        if the user is certain that the dataset contains multiple clusters. </span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : numpy.ndarray (2D)</span>
<span class="sd">            The input dataset.</span>
<span class="sd">        labels : numpy.array (1D), optional</span>
<span class="sd">            The corresponding labels if the dataset contains multiple classes.</span>
<span class="sd">        centers : numpy.ndarray (2D), optional</span>
<span class="sd">            A list [C1, ..., Cn] of n initial d-dimensional cluster centers </span>
<span class="sd">            Ci = [Ci_0, ..., Ci_d]. If those centers are not provided, the clustering will</span>
<span class="sd">            be initialized with KMeans for the K that optimizes the Silhouette score.</span>

<span class="sd">	References</span>
<span class="sd">	----------</span>
<span class="sd">	.. [1] Katharina Dost, Hamish Duncanson, Ioannis Ziogas, Patricia Riddle, and Jörg</span>
<span class="sd">           Wicker. &quot;Divide and Imitate: Multi-Cluster Identification and Mitigation of </span>
<span class="sd">           Selection Bias.&quot; In: Advances in Knowledge Discovery and Data Mining - 26th </span>
<span class="sd">           Pacific-Asia Conference, PAKDD 2022. Lecture Notes in Computer Science, vol. </span>
<span class="sd">           13281, pp. 149-160. Springer, Cham (2022).</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from imitatebias.generators import *</span>
<span class="sd">        &gt;&gt;&gt; from imitatebias.mimic import *</span>

<span class="sd">        Generate a dataset.</span>
<span class="sd">        &gt;&gt;&gt; X, y = generateData(1000, 2, 2, seed=2210)</span>

<span class="sd">        Generate a biased dataset.</span>
<span class="sd">        &gt;&gt;&gt; X_b, y_b, idcs_deleted = generateBias(X, y, 1, seed=2210)</span>

<span class="sd">        initialize Mimic</span>
<span class="sd">        &gt;&gt;&gt; mim = Mimic()</span>

<span class="sd">        fit to the biased dataset</span>
<span class="sd">        &gt;&gt;&gt; mim.fit(X_b, labels=y_b)</span>



<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">labels</span>

        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">):</span>
            <span class="n">d</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">==</span> <span class="n">l</span><span class="p">]</span>
            <span class="n">k_init</span> <span class="o">=</span> <span class="n">findK</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
            <span class="c1"># params = mean/cov for each cluster</span>
            <span class="n">probs_imi</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <span class="n">run_mimic</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">k_init</span><span class="o">=</span><span class="n">k_init</span><span class="p">)</span>

            <span class="c1"># merge the resulting clusters</span>
            <span class="n">probs_merge</span><span class="p">,</span> <span class="n">params_merge</span> <span class="o">=</span> <span class="n">merge</span><span class="p">(</span><span class="n">probs_imi</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>

            <span class="c1"># store parameters</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="n">params_merge</span>

    <span class="k">def</span> <span class="nf">predict_cluster</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">which_class</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Predicts clusters for the input data.</span>

<span class="sd">        Assigns clusters to the input data belonging to a specified class. Those clusters</span>
<span class="sd">        are selected based on the maximum probability that a point belongs to each of the </span>
<span class="sd">        clusters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        which_class : int</span>
<span class="sd">            Filters the data based on the initial labels.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        numpy.array (1D)</span>
<span class="sd">            The array containing the assigned clusters.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from imitatebias.generators import *</span>
<span class="sd">        &gt;&gt;&gt; from imitatebias.mimic import *</span>
<span class="sd">        &gt;&gt;&gt; import matplotlib.pyplot as plt</span>

<span class="sd">        Generate a dataset.</span>
<span class="sd">        &gt;&gt;&gt; X, y = generateData(1000, 2, 2, seed=2210)</span>

<span class="sd">        Generate a biased dataset.</span>
<span class="sd">        &gt;&gt;&gt; X_b, y_b, idcs_deleted = generateBias(X, y, 1, seed=2210)</span>

<span class="sd">        initialize Mimic</span>
<span class="sd">        &gt;&gt;&gt; mim = Mimic()</span>

<span class="sd">        fit to the biased dataset</span>
<span class="sd">        &gt;&gt;&gt; mim.fit(X_b, labels=y_b)</span>

<span class="sd">        predict cluster assignment for class 0</span>
<span class="sd">        &gt;&gt;&gt; predicted_clusters = mim.predict_cluster(0)</span>

<span class="sd">        plot the resulting clusters for class 0</span>
<span class="sd">        &gt;&gt;&gt; plt.scatter(X_b[y_b == 0, 0], X_b[y_b == 0, 1], c=predicted_clusters)</span>
<span class="sd">        &gt;&gt;&gt; plt.show()</span>



<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">l</span> <span class="o">=</span> <span class="n">which_class</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">l</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">l</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="o">==</span><span class="n">l</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">l</span><span class="p">]))])</span>
        <span class="k">return</span> <span class="n">prob_cluster_assignment</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">augment</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Augments the fitted dataset to mitigate its bias.</span>

<span class="sd">        Generates points to fill in the gap between fitted and observed distributions</span>
<span class="sd">        in the input dataset.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        numpy.ndarray (2D)</span>
<span class="sd">            Generated points.</span>
<span class="sd">        numpy.array (1D)</span>
<span class="sd">            Corresponding class labels.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from imitatebias.generators import *</span>
<span class="sd">        &gt;&gt;&gt; from imitatebias.mimic import *</span>
<span class="sd">        &gt;&gt;&gt; import matplotlib.pyplot as plt</span>

<span class="sd">        Generate a dataset.</span>
<span class="sd">        &gt;&gt;&gt; X, y = generateData(1000, 2, 2, seed=2210)</span>

<span class="sd">        Generate a biased dataset.</span>
<span class="sd">        &gt;&gt;&gt; X_b, y_b, idcs_deleted = generateBias(X, y, 1, seed=2210)</span>

<span class="sd">        initialize Mimic</span>
<span class="sd">        &gt;&gt;&gt; mim = Mimic()</span>

<span class="sd">        fit to the biased dataset</span>
<span class="sd">        &gt;&gt;&gt; mim.fit(X_b, labels=y_b)</span>

<span class="sd">        augment the data</span>
<span class="sd">        &gt;&gt;&gt; gen_p, gen_l = mim.augment()</span>

<span class="sd">        plot the result</span>
<span class="sd">        &gt;&gt;&gt; plt.scatter(X_b[:,0], X_b[:,1], label=&#39;dataset&#39;)</span>
<span class="sd">        &gt;&gt;&gt; plt.scatter(gen_p[:,0], gen_p[:,1], label=&#39;generated points&#39;)</span>
<span class="sd">        &gt;&gt;&gt; plt.legend()</span>
<span class="sd">        &gt;&gt;&gt; plt.show()</span>



<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">gen_points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span>
        <span class="n">gen_labels</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">):</span>
            <span class="n">cl_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_cluster</span><span class="p">(</span><span class="n">l</span><span class="p">)</span>
            <span class="n">data_clean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="o">==</span><span class="n">l</span><span class="p">][</span><span class="n">cl_labels</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">]</span>
            <span class="n">cl_labels_clean</span> <span class="o">=</span> <span class="n">cl_labels</span><span class="p">[</span><span class="n">cl_labels</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">]</span>

            <span class="n">points</span><span class="p">,</span> <span class="n">point_cl_labels</span> <span class="o">=</span> <span class="n">Mimic_augment</span><span class="p">(</span><span class="n">data_clean</span><span class="p">,</span> <span class="n">cl_labels_clean</span><span class="p">)</span>
            <span class="n">gen_points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">gen_points</span><span class="p">,</span> <span class="n">points</span><span class="p">))</span>
            <span class="n">gen_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gen_labels</span><span class="p">,</span> <span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">points</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">gen_points</span><span class="p">,</span> <span class="n">gen_labels</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h3 id="imitatebias.mimic.Mimic.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Mimic Constructor.</p>

      <details class="quote">
        <summary>Source code in <code>imitatebias\mimic.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Mimic Constructor.&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="p">{}</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="imitatebias.mimic.Mimic.augment" class="doc doc-heading">
<code class="highlight language-python"><span class="n">augment</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Augments the fitted dataset to mitigate its bias.</p>
<p>Generates points to fill in the gap between fitted and observed distributions
in the input dataset.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>numpy.ndarray (2D)</code>
          </td>
          <td><p>Generated points.</p></td>
        </tr>
        <tr>
          <td>
                <code>numpy.array (1D)</code>
          </td>
          <td><p>Corresponding class labels.</p></td>
        </tr>
    </tbody>
  </table>

<p><strong>Examples:</strong></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">imitatebias.generators</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">imitatebias.mimic</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</code></pre></div>
    <p>Generate a dataset.</p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">generateData</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2210</span><span class="p">)</span>
</code></pre></div>
    <p>Generate a biased dataset.</p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">X_b</span><span class="p">,</span> <span class="n">y_b</span><span class="p">,</span> <span class="n">idcs_deleted</span> <span class="o">=</span> <span class="n">generateBias</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2210</span><span class="p">)</span>
</code></pre></div>
    <p>initialize Mimic</p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">mim</span> <span class="o">=</span> <span class="n">Mimic</span><span class="p">()</span>
</code></pre></div>
    <p>fit to the biased dataset</p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">mim</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_b</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">y_b</span><span class="p">)</span>
</code></pre></div>
    <p>augment the data</p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">gen_p</span><span class="p">,</span> <span class="n">gen_l</span> <span class="o">=</span> <span class="n">mim</span><span class="o">.</span><span class="n">augment</span><span class="p">()</span>
</code></pre></div>
    <p>plot the result</p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_b</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_b</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;dataset&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">gen_p</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">gen_p</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;generated points&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>

      <details class="quote">
        <summary>Source code in <code>imitatebias\mimic.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">augment</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Augments the fitted dataset to mitigate its bias.</span>

<span class="sd">    Generates points to fill in the gap between fitted and observed distributions</span>
<span class="sd">    in the input dataset.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    numpy.ndarray (2D)</span>
<span class="sd">        Generated points.</span>
<span class="sd">    numpy.array (1D)</span>
<span class="sd">        Corresponding class labels.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from imitatebias.generators import *</span>
<span class="sd">    &gt;&gt;&gt; from imitatebias.mimic import *</span>
<span class="sd">    &gt;&gt;&gt; import matplotlib.pyplot as plt</span>

<span class="sd">    Generate a dataset.</span>
<span class="sd">    &gt;&gt;&gt; X, y = generateData(1000, 2, 2, seed=2210)</span>

<span class="sd">    Generate a biased dataset.</span>
<span class="sd">    &gt;&gt;&gt; X_b, y_b, idcs_deleted = generateBias(X, y, 1, seed=2210)</span>

<span class="sd">    initialize Mimic</span>
<span class="sd">    &gt;&gt;&gt; mim = Mimic()</span>

<span class="sd">    fit to the biased dataset</span>
<span class="sd">    &gt;&gt;&gt; mim.fit(X_b, labels=y_b)</span>

<span class="sd">    augment the data</span>
<span class="sd">    &gt;&gt;&gt; gen_p, gen_l = mim.augment()</span>

<span class="sd">    plot the result</span>
<span class="sd">    &gt;&gt;&gt; plt.scatter(X_b[:,0], X_b[:,1], label=&#39;dataset&#39;)</span>
<span class="sd">    &gt;&gt;&gt; plt.scatter(gen_p[:,0], gen_p[:,1], label=&#39;generated points&#39;)</span>
<span class="sd">    &gt;&gt;&gt; plt.legend()</span>
<span class="sd">    &gt;&gt;&gt; plt.show()</span>



<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">gen_points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span>
    <span class="n">gen_labels</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">):</span>
        <span class="n">cl_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_cluster</span><span class="p">(</span><span class="n">l</span><span class="p">)</span>
        <span class="n">data_clean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="o">==</span><span class="n">l</span><span class="p">][</span><span class="n">cl_labels</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">cl_labels_clean</span> <span class="o">=</span> <span class="n">cl_labels</span><span class="p">[</span><span class="n">cl_labels</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">]</span>

        <span class="n">points</span><span class="p">,</span> <span class="n">point_cl_labels</span> <span class="o">=</span> <span class="n">Mimic_augment</span><span class="p">(</span><span class="n">data_clean</span><span class="p">,</span> <span class="n">cl_labels_clean</span><span class="p">)</span>
        <span class="n">gen_points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">gen_points</span><span class="p">,</span> <span class="n">points</span><span class="p">))</span>
        <span class="n">gen_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gen_labels</span><span class="p">,</span> <span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">points</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">gen_points</span><span class="p">,</span> <span class="n">gen_labels</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="imitatebias.mimic.Mimic.fit" class="doc doc-heading">
<code class="highlight language-python"><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[],</span> <span class="n">centers</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Fits a bias-aware multivariate Gaussian Mixture Model per label to the data.</p>
<p>See our paper [1]_ for details. This process is slow and substantially less
powerful than the Imitate algorithm since it additionally needs to cluster the
dataset into potentially biased overlapping clusters. We only recommend Mimic
if the user is certain that the dataset contains multiple clusters. </p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>data</code></td>
          <td>
                <code>numpy.ndarray (2D)</code>
          </td>
          <td><p>The input dataset.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>labels</code></td>
          <td>
                <code>numpy.array (1D), optional</code>
          </td>
          <td><p>The corresponding labels if the dataset contains multiple classes.</p></td>
          <td>
                <code>[]</code>
          </td>
        </tr>
        <tr>
          <td><code>centers</code></td>
          <td>
                <code>numpy.ndarray (2D), optional</code>
          </td>
          <td><p>A list [C1, ..., Cn] of n initial d-dimensional cluster centers 
Ci = [Ci_0, ..., Ci_d]. If those centers are not provided, the clustering will
be initialized with KMeans for the K that optimizes the Silhouette score.</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>
      <h5 id="imitatebias.mimic.Mimic.fit--references">References</h5>
<p>.. [1] Katharina Dost, Hamish Duncanson, Ioannis Ziogas, Patricia Riddle, and Jörg
   Wicker. "Divide and Imitate: Multi-Cluster Identification and Mitigation of 
   Selection Bias." In: Advances in Knowledge Discovery and Data Mining - 26th 
   Pacific-Asia Conference, PAKDD 2022. Lecture Notes in Computer Science, vol. 
   13281, pp. 149-160. Springer, Cham (2022).</p>

<p><strong>Examples:</strong></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">imitatebias.generators</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">imitatebias.mimic</span> <span class="kn">import</span> <span class="o">*</span>
</code></pre></div>
    <p>Generate a dataset.</p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">generateData</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2210</span><span class="p">)</span>
</code></pre></div>
    <p>Generate a biased dataset.</p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">X_b</span><span class="p">,</span> <span class="n">y_b</span><span class="p">,</span> <span class="n">idcs_deleted</span> <span class="o">=</span> <span class="n">generateBias</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2210</span><span class="p">)</span>
</code></pre></div>
    <p>initialize Mimic</p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">mim</span> <span class="o">=</span> <span class="n">Mimic</span><span class="p">()</span>
</code></pre></div>
    <p>fit to the biased dataset</p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">mim</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_b</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">y_b</span><span class="p">)</span>
</code></pre></div>

      <details class="quote">
        <summary>Source code in <code>imitatebias\mimic.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span></pre></div></td><td class="code"><div><pre><span></span><code>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[],</span> <span class="n">centers</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Fits a bias-aware multivariate Gaussian Mixture Model per label to the data.</span>

<span class="sd">        See our paper [1]_ for details. This process is slow and substantially less</span>
<span class="sd">        powerful than the Imitate algorithm since it additionally needs to cluster the</span>
<span class="sd">        dataset into potentially biased overlapping clusters. We only recommend Mimic</span>
<span class="sd">        if the user is certain that the dataset contains multiple clusters. </span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : numpy.ndarray (2D)</span>
<span class="sd">            The input dataset.</span>
<span class="sd">        labels : numpy.array (1D), optional</span>
<span class="sd">            The corresponding labels if the dataset contains multiple classes.</span>
<span class="sd">        centers : numpy.ndarray (2D), optional</span>
<span class="sd">            A list [C1, ..., Cn] of n initial d-dimensional cluster centers </span>
<span class="sd">            Ci = [Ci_0, ..., Ci_d]. If those centers are not provided, the clustering will</span>
<span class="sd">            be initialized with KMeans for the K that optimizes the Silhouette score.</span>

<span class="sd">	References</span>
<span class="sd">	----------</span>
<span class="sd">	.. [1] Katharina Dost, Hamish Duncanson, Ioannis Ziogas, Patricia Riddle, and Jörg</span>
<span class="sd">           Wicker. &quot;Divide and Imitate: Multi-Cluster Identification and Mitigation of </span>
<span class="sd">           Selection Bias.&quot; In: Advances in Knowledge Discovery and Data Mining - 26th </span>
<span class="sd">           Pacific-Asia Conference, PAKDD 2022. Lecture Notes in Computer Science, vol. </span>
<span class="sd">           13281, pp. 149-160. Springer, Cham (2022).</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from imitatebias.generators import *</span>
<span class="sd">        &gt;&gt;&gt; from imitatebias.mimic import *</span>

<span class="sd">        Generate a dataset.</span>
<span class="sd">        &gt;&gt;&gt; X, y = generateData(1000, 2, 2, seed=2210)</span>

<span class="sd">        Generate a biased dataset.</span>
<span class="sd">        &gt;&gt;&gt; X_b, y_b, idcs_deleted = generateBias(X, y, 1, seed=2210)</span>

<span class="sd">        initialize Mimic</span>
<span class="sd">        &gt;&gt;&gt; mim = Mimic()</span>

<span class="sd">        fit to the biased dataset</span>
<span class="sd">        &gt;&gt;&gt; mim.fit(X_b, labels=y_b)</span>



<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">labels</span>

        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">):</span>
            <span class="n">d</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">==</span> <span class="n">l</span><span class="p">]</span>
            <span class="n">k_init</span> <span class="o">=</span> <span class="n">findK</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
            <span class="c1"># params = mean/cov for each cluster</span>
            <span class="n">probs_imi</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <span class="n">run_mimic</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">k_init</span><span class="o">=</span><span class="n">k_init</span><span class="p">)</span>

            <span class="c1"># merge the resulting clusters</span>
            <span class="n">probs_merge</span><span class="p">,</span> <span class="n">params_merge</span> <span class="o">=</span> <span class="n">merge</span><span class="p">(</span><span class="n">probs_imi</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>

            <span class="c1"># store parameters</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="n">params_merge</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="imitatebias.mimic.Mimic.predict_cluster" class="doc doc-heading">
<code class="highlight language-python"><span class="n">predict_cluster</span><span class="p">(</span><span class="n">which_class</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Predicts clusters for the input data.</p>
<p>Assigns clusters to the input data belonging to a specified class. Those clusters
are selected based on the maximum probability that a point belongs to each of the 
clusters.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>which_class</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Filters the data based on the initial labels.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>numpy.array (1D)</code>
          </td>
          <td><p>The array containing the assigned clusters.</p></td>
        </tr>
    </tbody>
  </table>

<p><strong>Examples:</strong></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">imitatebias.generators</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">imitatebias.mimic</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</code></pre></div>
    <p>Generate a dataset.</p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">generateData</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2210</span><span class="p">)</span>
</code></pre></div>
    <p>Generate a biased dataset.</p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">X_b</span><span class="p">,</span> <span class="n">y_b</span><span class="p">,</span> <span class="n">idcs_deleted</span> <span class="o">=</span> <span class="n">generateBias</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2210</span><span class="p">)</span>
</code></pre></div>
    <p>initialize Mimic</p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">mim</span> <span class="o">=</span> <span class="n">Mimic</span><span class="p">()</span>
</code></pre></div>
    <p>fit to the biased dataset</p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">mim</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_b</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">y_b</span><span class="p">)</span>
</code></pre></div>
    <p>predict cluster assignment for class 0</p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">predicted_clusters</span> <span class="o">=</span> <span class="n">mim</span><span class="o">.</span><span class="n">predict_cluster</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>
    <p>plot the resulting clusters for class 0</p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_b</span><span class="p">[</span><span class="n">y_b</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_b</span><span class="p">[</span><span class="n">y_b</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">predicted_clusters</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>

      <details class="quote">
        <summary>Source code in <code>imitatebias\mimic.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">predict_cluster</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">which_class</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Predicts clusters for the input data.</span>

<span class="sd">    Assigns clusters to the input data belonging to a specified class. Those clusters</span>
<span class="sd">    are selected based on the maximum probability that a point belongs to each of the </span>
<span class="sd">    clusters.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    which_class : int</span>
<span class="sd">        Filters the data based on the initial labels.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    numpy.array (1D)</span>
<span class="sd">        The array containing the assigned clusters.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from imitatebias.generators import *</span>
<span class="sd">    &gt;&gt;&gt; from imitatebias.mimic import *</span>
<span class="sd">    &gt;&gt;&gt; import matplotlib.pyplot as plt</span>

<span class="sd">    Generate a dataset.</span>
<span class="sd">    &gt;&gt;&gt; X, y = generateData(1000, 2, 2, seed=2210)</span>

<span class="sd">    Generate a biased dataset.</span>
<span class="sd">    &gt;&gt;&gt; X_b, y_b, idcs_deleted = generateBias(X, y, 1, seed=2210)</span>

<span class="sd">    initialize Mimic</span>
<span class="sd">    &gt;&gt;&gt; mim = Mimic()</span>

<span class="sd">    fit to the biased dataset</span>
<span class="sd">    &gt;&gt;&gt; mim.fit(X_b, labels=y_b)</span>

<span class="sd">    predict cluster assignment for class 0</span>
<span class="sd">    &gt;&gt;&gt; predicted_clusters = mim.predict_cluster(0)</span>

<span class="sd">    plot the resulting clusters for class 0</span>
<span class="sd">    &gt;&gt;&gt; plt.scatter(X_b[y_b == 0, 0], X_b[y_b == 0, 1], c=predicted_clusters)</span>
<span class="sd">    &gt;&gt;&gt; plt.show()</span>



<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">l</span> <span class="o">=</span> <span class="n">which_class</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">l</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">l</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="o">==</span><span class="n">l</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">l</span><span class="p">]))])</span>
    <span class="k">return</span> <span class="n">prob_cluster_assignment</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>



  </div>

  </div>

</div>




  </div>

  </div>

</div>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
    <nav class="md-footer__inner md-grid" aria-label="Footer" >
      
        
        <a href="../imitate/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Imitate" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Imitate
            </div>
          </div>
        </a>
      
      
        
        <a href="../cancels/" class="md-footer__link md-footer__link--next" aria-label="Next: Cancels" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Cancels
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.5bf1dace.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.078830c0.min.js"></script>
      
    
  </body>
</html>